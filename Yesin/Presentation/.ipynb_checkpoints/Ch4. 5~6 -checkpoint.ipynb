{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why..🤔\n",
    "<img src=\"https://velog.velcdn.com/images/bailando/post/d492013a-ccf0-4ddc-acae-2d842622c3fd/image.png\" width=\"500\" height=\"250\">\n",
    "<img src=\"https://velog.velcdn.com/images/bailando/post/3b24d368-05bd-438a-bddd-0ecf8d44763e/image.jpeg\" width=\"500\" height=\"1000\">\n",
    "\n",
    "위와 같은 문제를 만났을 때 하나의 방향을 더 생각해 볼 수 있다~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- 4. 5 Handling Text Files ~~ 4. 6 Normalizing Unicode for Reliable Comparisons -->\n",
    "## 4. 5 텍스트 파일다루기\n",
    "텍스트를 처리하는 최고의 방법은 '유니코드 샌드위치'다.\n",
    "가능하면 bytes를 str로 변환해야 한다는 것을 의미한다.\n",
    "![](https://www.oreilly.com/api/v2/epubs/9781492056348/files/assets/flpy_0402.png)\n",
    "\n",
    "가능하면 빨리 bytes를 str으로 변환하고 가능한 늦게 str을 bytes로 변환한다. \n",
    "\n",
    "파이썬 3에서는 내장된 `open()` 함수를 통해 파일을 텍스트 모드로 읽고 쓸 때 필요한 인코딩과 디코딩 작업을 모두 수행해준다. \n",
    "따라서 file.read()에서 str객체를 가져와 처리하고 file.write()에 전달하면 된다.\n",
    "\n",
    "\n",
    "- reference\n",
    "    - [ASCII & Unicode](https://whatisthenext.tistory.com/103)\n",
    "    - [한글 인코딩의 이해](https://d2.naver.com/helloworld/19187)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('cafe.txt', 'w', encoding='utf_8').write('café')       # cafe.txt 파일에 'café' 문자열을 쓴다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'café'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('cafe.txt').read()                                     # bytes로 저장된 파일을 str로 읽는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('cafe.txt', 'w', encoding='utf_8')                  # cafe.txt 파일을 쓰기 모드로 열고, 인코딩은 utf_8로 한다.\n",
    "f.write('café')                                             # 'café' 문자열을 쓴다.\n",
    "f.close()                                                   # 파일을 닫는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.stat('cafe.txt').st_size                                 # 파일 크기를 알아낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'caf\\xc3\\xa9'\n",
      "5\n",
      "café\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "cafe_e = 'café'.encode()\n",
    "print(cafe_e)\n",
    "print(len(cafe_e))\n",
    "\n",
    "cafe_d = b'caf\\xc3\\xa9'.decode()\n",
    "print(cafe_d)\n",
    "print(len(cafe_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='cafe.txt' mode='r' encoding='UTF-8'>\n",
      "café\n"
     ]
    }
   ],
   "source": [
    "# Mac OS에서는 기본 인코딩으로 UTF-8 을 사용하고 있다.\n",
    "fp2 = open('cafe.txt')\n",
    "print(fp2)\n",
    "print(fp2.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='cafe.txt' mode='r' encoding='cp1252'>\n",
      "cafÃ©\n"
     ]
    }
   ],
   "source": [
    "# Windows 1252 인코딩 (cp1252)\n",
    "f3 = open('cafe.txt', encoding='cp1252')\n",
    "print(f3)\n",
    "print(f3.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.BufferedReader name='cafe.txt'>\n",
      "b'caf\\xc3\\xa9'\n"
     ]
    }
   ],
   "source": [
    "f4 = open('cafe.txt', 'rb')                       # 이진 모드로 읽는다.\n",
    "print(f4)\n",
    "print(f4.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 5. 1 기본 인코딩 설정: 정신 나간 거 아냐?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " locale.getpreferredencoding() -> 'UTF-8'\n",
      "                 type(my_file) -> <class '_io.TextIOWrapper'>\n",
      "              my_file.encoding -> 'UTF-8'\n",
      "           sys.stdout.isatty() -> False\n",
      "           sys.stdout.encoding -> 'UTF-8'\n",
      "            sys.stdin.isatty() -> False\n",
      "            sys.stdin.encoding -> 'utf-8'\n",
      "           sys.stderr.isatty() -> False\n",
      "           sys.stderr.encoding -> 'UTF-8'\n",
      "      sys.getdefaultencoding() -> 'utf-8'\n",
      "   sys.getfilesystemencoding() -> 'utf-8'\n"
     ]
    }
   ],
   "source": [
    "# 시스템 기본 인코딩 알아보기\n",
    "import sys\n",
    "import locale\n",
    "\n",
    "expression = \"\"\"\n",
    "        locale.getpreferredencoding()\n",
    "        type(my_file)\n",
    "        my_file.encoding\n",
    "        sys.stdout.isatty()\n",
    "        sys.stdout.encoding\n",
    "        sys.stdin.isatty()\n",
    "        sys.stdin.encoding\n",
    "        sys.stderr.isatty()\n",
    "        sys.stderr.encoding\n",
    "        sys.getdefaultencoding()\n",
    "        sys.getfilesystemencoding()\n",
    "    \"\"\"\n",
    "\n",
    "my_file = open('dummy', 'w')\n",
    "\n",
    "for expression in expression.split():\n",
    "    value = eval(expression)\n",
    "    print(expression.rjust(30), '->', repr(value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "locale.getpreferredencoding() 설정이 가장 중요하다. 이 함수를 통해 기본 텍스트 파일을 열고, 표준 입출력(sys.stdout, sys.stderr)을 리다이렉션할 때도 사용된다.\n",
    "\n",
    "> **locale.getpreferrendencoding(do_setlocale=True)**\\\n",
    "사용자 환경에 따라 텍스트 데이터에 사용되는 인코딩을 반환한다. 이 함수가 반환하는 값은 추정치이다.\n",
    "\n",
    "즉! '기본 인코딩에 의존하지 않는 것'이 가장 좋다!\n",
    "유니코드 샌드위치 모델을 따르고 프로그램 내에서 항상 인코딩을 명시하면 많은 문제를 피할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 6 제대로 비교하기 위해 유니코드 정규화하기\n",
    "유니코드에는 결합 문자가 있기 때문에 문자열 비교가 간단하지 않다. 앞 문자에 연결되는 발음 구별 기호(diacritical mark)는 인쇄할 때 앞 문자와 결합되어 출력된다.\n",
    "\n",
    "'café'라는 단어를 예로 들면 cafe의 e에 액센트 기호가 붙은 것이다.\n",
    "따라 해당 문자열은 'café'와 'cafe\\u0301' 두 가지 방식으로 표현할 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "café café\n",
      "4 5\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "s1 = 'café'\n",
    "s2 = 'cafe\\u0301'\n",
    "\n",
    "print(s1, s2)\n",
    "print(len(s1), len(s2))\n",
    "print(s1 == s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'e'\n",
      "b'e\\xcc\\x81\\xcc\\x81\\xcc\\x81'\n"
     ]
    }
   ],
   "source": [
    "print('e'.encode(encoding='utf_8'))\n",
    "\n",
    "print('é́́'.encode(encoding='utf_8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드 포인트 `U+0301`은 *COMBINING CUTE ACCENT*다. 'e'에 붙어서 'é'를 만든다. \n",
    "\n",
    "e +  ́ -> é é́ é́́ é́́́ é́́́́\n",
    "\n",
    "유니코드 표준에서는 따라서 'é'와 'e\\u0301'은 규범적으로 동일하다고 하며, 애플리케이션은 두 시퀀스를 동일하게 처리해야 한다. 하지만 파이썬은 두 개의 코드 포인트 시퀀스를 보고 동일하지 않다고 판단한다.\n",
    "\n",
    "이 문제를 해결하려면 Unicodedata.normalize() 함수가 제공하는 유니코드 정규화를 이용해야 한다. 이 함수의 첫 번째 인수는 'NFC', 'NFD', 'NFKC', 'NFKD' 네 가지 중 하나다. \n",
    "\n",
    "- NFC: 코드 포인트를 조합해서 짧은 문자열 생성\n",
    "- NFD: 기본 문자와 결합 문자로 분리한다.\n",
    "\n",
    "**이중 'NFC'는 W3C가 추천하는 정규화 형식**이므로 안전하게 `normalize('NFC', user_text)`하는 것이 권장된다.\n",
    "\n",
    "(전기 저항을 나타내는 옴기호는 그리스어 대문자 오메가로 정규화된다. 겉모습은 똑같지만 다르다고 판단되므로 정규화해서 뜻하지 않은 문제를 예방해야 한다.)\n",
    "\n",
    "\n",
    "[Unicode-table](https://unicode-table.com/kr/0301/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 5\n",
      "4 4\n",
      "5 5\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize\n",
    "\n",
    "s1 = 'café'\n",
    "s2 = 'cafe\\u0301'\n",
    "\n",
    "print(len(s1), len(s2))\n",
    "print(len(normalize('NFC', s1)), len(normalize('NFC', s2)))\n",
    "print(len(normalize('NFD', s1)), len(normalize('NFD', s2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ohm: OHM SIGN\n",
      "                norm_ohm: GREEK CAPITAL LETTER OMEGA\n",
      "            ohm == ohm_c: False\n",
      "  norm_ohm == norm_hom_c: True\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize, name\n",
    "\n",
    "ohm = '\\u2126'\n",
    "ohm_c = normalize('NFC', ohm)\n",
    "\n",
    "print(\"ohm:\".rjust(25), name(ohm))\n",
    "print(\"norm_ohm:\".rjust(25), name(ohm_c))\n",
    "print(\"ohm == ohm_c:\".rjust(25), ohm == ohm_c)\n",
    "print(\"norm_ohm == norm_hom_c:\".rjust(25), normalize('NFC', ohm) == normalize('NFC', ohm_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NFKC의 K는 호환성(Compatibility)을 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1⁄2\n",
      "1⁄2\n",
      "3 3\n",
      "42\n",
      "42\n",
      "2 2\n"
     ]
    }
   ],
   "source": [
    "# NFKC\n",
    "half = '½'\n",
    "print(normalize('NFKC', half))\n",
    "print(normalize('NFKD', half))\n",
    "\n",
    "print(len(normalize('NFKC', half)), len(normalize('NFKD', half)))\n",
    "\n",
    "four_squared = '4²'\n",
    "print(normalize('NFKC', four_squared))\n",
    "print(normalize('NFKD', four_squared))\n",
    "print(len(normalize('NFKC', four_squared)), len(normalize('NFKD', four_squared)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "µ μ\n",
      "181 956\n",
      "MICRO SIGN, GREEK SMALL LETTER MU\n"
     ]
    }
   ],
   "source": [
    "# NFKD\n",
    "micro = 'µ'\n",
    "micro_kc = normalize('NFKC', micro)\n",
    "\n",
    "print(micro, micro_kc)\n",
    "print(ord(micro), ord(micro_kc))        # ord() : 문자의 유니코드 코드 포인트를 반환\n",
    "print(name(micro), name(micro_kc), sep=\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NFKC와 NFKD normalization은 저장할 때에는 사용하지 않는다. \n",
    "\n",
    "다만, 검색이나 색인 생성 등의 작업을 할 때 유용하다.\n",
    "\n",
    "1/2를 검색해서 ½ 를 찾을 수 있다면 사용자가 정말 기쁘겠죠?!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 6. 1 케이스 폴딩\n",
    "case folding은 모든 텍스트를 소문자로 변환하는 연산이며, 약간의 변환을 동반한다. 케이스 폴딩은 `str.casefold()` 메서드를 통해 수행할 수 있다.\n",
    "\n",
    "latin1 문자만 담고 있는 문자열인 경우 s.casefold()와 s.lower()는 같은 결과를 반환한다. 하지만 유니코드 문자열에 대해서는 다르다.\n",
    "micro 기호(µ)는 동일해 보이지만 그리스 문자 μ로 변환되며, 샤프에스라고 불리는 독일어 에스체트 기호(ẞ)는 ss로 변환된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MICRO SIGN\n",
      "MICRO SIGN\n",
      "GREEK SMALL LETTER MU\n",
      "µ μ µ\n"
     ]
    }
   ],
   "source": [
    "micro = 'µ'\n",
    "micro_low = micro.lower()\n",
    "micro_cf = micro.casefold()\n",
    "\n",
    "print(name(micro))\n",
    "print(name(micro_low))          # low() 를 통해서는 변환되지 않음 \n",
    "print(name(micro_cf))\n",
    "print(micro, micro_cf, micro_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "micro 기호는 lower()를 통해 변환되지 않고 casefold()를 통해 그리스어 mu의 소문자로 변환된다. \n",
    "lower()와 casefold()가 서로 다른 문자를 반환하는 코드 포인트는 python 3.4 기준 116개라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LATIN SMALL LETTER SHARP S\n",
      "LATIN SMALL LETTER S\n",
      "ß ss\n"
     ]
    }
   ],
   "source": [
    "eszett = 'ß'\n",
    "eszett_cf = eszett.casefold()\n",
    "\n",
    "print(name(eszett))\n",
    "print(name(eszett_cf[0]))\n",
    "print(eszett, eszett_cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q? micro 기호는 normalize와 casefold한 결과가 같다. 그렇다면 왜 casefold를 사용해야 할까? casefold도 정규화의 일종이라고 할 수 있을까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OHM SIGN\n",
      "GREEK SMALL LETTER OMEGA\n",
      "ω\n",
      "ω\n",
      "GREEK CAPITAL LETTER OMEGA\n",
      "GREEK SMALL LETTER OMEGA\n"
     ]
    }
   ],
   "source": [
    "print(name(ohm))\n",
    "print(name(ohm.lower()))\n",
    "\n",
    "print(ohm.lower())\n",
    "print(ohm.casefold())\n",
    "\n",
    "print(name(normalize('NFC', ohm)))\n",
    "print(name(ohm.casefold()))         # 정규화된 ohm의 소문자를 반환해줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 6. 2 정규화된 텍스트 매칭을 위한 유틸리티 함수\n",
    "최종적으로 정리하자면 NFC는 대부분의 애플리케이션에서 사용할 수 있는 최적의 정규화된 형태이고, str.casefold()는 대소문자를 구분 없이 문자를 비교할 때 가장 좋은 방법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from normep import nfc_equal, fold_equal\n",
    "\n",
    "s1 = 'café'\n",
    "s2 = 'cafe\\u0301'\n",
    "\n",
    "print(s1 == s2)\n",
    "print(nfc_equal(s1, s2))\n",
    "print(fold_equal(s1, s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "s3 = 'Straße'\n",
    "s4 = 'strasse'\n",
    "\n",
    "print(s3 == s4)\n",
    "print(nfc_equal(s3, s4))\n",
    "print(fold_equal(s3, s4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 6. 3 극단적인 '정규화': 발음 구별 기호 제거하기\n",
    "발음 구별 기호를 제고하는 것은 오탐이 발생할 수 있지만 너무 연연하지 말자!\n",
    "액센트나 갈고리형 기호 등의 발음 기호를 제거하면 가독성이 높아진다.\n",
    "\n",
    "`https://en.wikipedia.org/wiki/S%C3%A3o_Paulo` 를 `https://en.wikipedia.org/wiki/Sao_Paulo` 로 변환하는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acai\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def shave_marks(txt):\n",
    "    \"\"\"발음 구별 기호를 모두 제거한다.\"\"\"\n",
    "    \n",
    "    # NFD 정규화로 문자와 기호를 분해\n",
    "    norm_txt = normalize('NFD', txt)   \n",
    "    \n",
    "    # unicodedata.combining() 함수로 문자의 결합형 분류값을 구하고, 결합형 분류값이 0인 문자만 남긴다.\n",
    "    shaved = ''.join(c for c in norm_txt if not unicodedata.combining(c))\n",
    "    return normalize('NFC', shaved)\n",
    "\n",
    "\n",
    "order = '“Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.”'\n",
    "order = 'açaí'\n",
    "print(shave_marks(order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“Herr Voß: • ½ cup of Œtker™ caffe latte • bowl of acai.”\n",
      "Ζεφυρος, Zefiro\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "from torch import greater_equal\n",
    "\n",
    "def shave_marks(txt):\n",
    "    \"\"\"발음 구별 기호를 모두 제거한다.\"\"\"\n",
    "    \n",
    "    # NFD 정규화로 문자와 기호를 분해\n",
    "    norm_txt = normalize('NFD', txt)   \n",
    "    \n",
    "    # unicodedata.combining(): 결합문자열을 정수로 반환. 문자열이 결합문자가 아니면 0을 반환\n",
    "    shaved = ''.join(c for c in norm_txt if not unicodedata.combining(c))\n",
    "\n",
    "    return normalize('NFC', shaved)\n",
    "\n",
    "\n",
    "order = '“Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.”'\n",
    "greek = 'Ζέφυρος, Zéfiro'\n",
    "\n",
    "\n",
    "print(shave_marks(order))\n",
    "print(shave_marks(greek))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`έ`는 어차피 아스키코드에도 없는 문잔데, 극단적으로 액센트를 적용할 필요 없다! 아스키코드에 있는 것은 살려두자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“Herr Voß: • ½ cup of Œtker™ caffe latte • bowl of acai.”\n",
      "Ζέφυρος, Zefiro\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def shave_marks_latin(txt):\n",
    "    \"\"\"라틴 기반 문자에서 발음 구별 기호를 모두 제거한다.\"\"\"\n",
    "\n",
    "    norm_txt = unicodedata.normalize('NFD', txt)\n",
    "    latin_balse = False\n",
    "    keepers = []\n",
    "\n",
    "    for c in norm_txt:\n",
    "        if unicodedata.combining(c) and latin_base:\n",
    "            continue    \n",
    "        keepers.append(c)\n",
    "        \n",
    "        # c가 라틴 문자인지 확인\n",
    "        if not unicodedata.combining(c):\n",
    "            latin_base = c in string.ascii_letters\n",
    "    shaved = ''.join(keepers)\n",
    "    return unicodedata.normalize('NFC', shaved)\n",
    "\n",
    "\n",
    "\n",
    "order = '“Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.”'\n",
    "greek = 'Ζέφυρος, Zéfiro'\n",
    "\n",
    "print(shave_marks_latin(order))\n",
    "print(shave_marks_latin(greek))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Herr Voß: - ½ cup of OEtker(TM) caffè latte - bowl of açaí.\"\n",
      "\"Herr Voss: - 1⁄2 cup of OEtker(TM) caffe latte - bowl of acai.\"\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/fluentpython/example-code/blob/master/04-text-byte/sanitize.py\n",
    "\n",
    "single_map = str.maketrans(\"\"\"‚ƒ„†ˆ‹‘’“”•–—˜›\"\"\",  \n",
    "                           \"\"\"'f\"*^<''\"\"---~>\"\"\")\n",
    "\n",
    "multi_map = str.maketrans({  \n",
    "    '€': '<euro>',\n",
    "    '…': '...',\n",
    "    'Œ': 'OE',\n",
    "    '™': '(TM)',\n",
    "    'œ': 'oe',\n",
    "    '‰': '<per mille>',\n",
    "    '‡': '**',\n",
    "})\n",
    "\n",
    "multi_map.update(single_map)  \n",
    "\n",
    "\n",
    "def dewinize(txt):\n",
    "    \"\"\"Replace Win1252 symbols with ASCII chars or sequences\"\"\"\n",
    "    return txt.translate(multi_map)  \n",
    "\n",
    "\n",
    "def asciize(txt):\n",
    "    no_marks = shave_marks_latin(dewinize(txt))     \n",
    "    no_marks = no_marks.replace('ß', 'ss')          \n",
    "    return unicodedata.normalize('NFKC', no_marks) \n",
    "\n",
    "\n",
    "order = '“Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.”'\n",
    "\n",
    "print(dewinize(order))\n",
    "print(asciize(order))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 텍스트 정규화를 해줄 수 있는 코드를 만나보았습니다.\n",
    "언젠가 유용하게 쓸 수 있는 날을 기대해봅시다...!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "391b1e7ce2e81530d6fa13507e2cf4fd1c09c0aaf5e54d082942efacf0dd49e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
